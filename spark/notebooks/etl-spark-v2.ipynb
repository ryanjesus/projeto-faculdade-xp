{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf8d6ca-5b92-4519-a38d-79568b72ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12099fb2-36ad-4584-9900-888ed985195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL Pipeline - Bronze to Silver\") \\\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/hadoop-aws-3.3.4.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.262.jar\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a0fbcd8-850d-47bf-b14b-3fe68e5d49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_path = \"s3a://my-bucket-ry-01/raw-data/ipca/kafka/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec2a400-931e-4056-b713-32ad506fd91c",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o35.json.\n: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2688)\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3431)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)\n\tat org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:362)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\nCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n\tat org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2592)\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2686)\n\t... 29 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_bronze \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbronze_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:425\u001b[0m, in \u001b[0;36mDataFrameReader.json\u001b[0;34m(self, path, schema, primitivesAsString, prefersDecimal, allowComments, allowUnquotedFieldNames, allowSingleQuotes, allowNumericLeadingZero, allowBackslashEscapingAnyCharacter, mode, columnNameOfCorruptRecord, dateFormat, timestampFormat, multiLine, allowUnquotedControlChars, lineSep, samplingRatio, dropFieldIfAllNull, encoding, locale, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, allowNonNumericNumbers)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator: Iterable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o35.json.\n: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2688)\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3431)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)\n\tat org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.json(DataFrameReader.scala:362)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\nCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n\tat org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2592)\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2686)\n\t... 29 more\n"
     ]
    }
   ],
   "source": [
    "df_bronze = spark.read.json(bronze_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "460eb66c-3cda-4b57-a094-8e2ed6386bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------------+-----------+-------------+------------+----+----------+-------------+---------+\n",
      "|CompraManha|    Data_Base|Data_Vencimento|PUBaseManha|PUCompraManha|PUVendaManha|Tipo|VendaManha|    dt_update|partition|\n",
      "+-----------+-------------+---------------+-----------+-------------+------------+----+----------+-------------+---------+\n",
      "|       6.35|1719187200000|  1786752000000|    3753.72|      3764.16|     3753.72|IPCA|      6.47|1743228344967|        0|\n",
      "|      10.27|1719187200000|  1723680000000|    4230.97|      4233.79|     4230.97|IPCA|     10.39|1743228344968|        0|\n",
      "|      -1.29|1556755200000|  1557878400000|    3219.03|      3219.66|     3219.54|IPCA|     -1.17|1743228349406|        0|\n",
      "|       4.43|1556582400000|  2378419200000|    1013.05|      1044.31|     1013.64|IPCA|      4.55|1743228349407|        0|\n",
      "|      -1.49|1556236800000|  1557878400000|    3215.88|      3217.83|     3217.66|IPCA|     -1.37|1743228349417|        0|\n",
      "|       4.16|1556236800000|  1723680000000|    2574.76|      2592.49|     2576.75|IPCA|      4.28|1743228349418|        0|\n",
      "|       4.46|1556064000000|  2378419200000|    1003.38|      1034.13|     1003.74|IPCA|      4.58|1743228349455|        0|\n",
      "|      -0.54|1556064000000|  1557878400000|    3212.55|      3213.27|     3213.07|IPCA|     -0.42|1743228349456|        0|\n",
      "|       0.07|1427241600000|  1431648000000|    2588.01|      2589.26|     2589.19|IPCA|      0.09|1743228352724|        0|\n",
      "|      -0.23|1427155200000|  1431648000000|    2587.91|      2589.13|     2589.06|IPCA|     -0.21|1743228352725|        0|\n",
      "|      -0.39|1427068800000|  1431648000000|    2587.36|      2588.56|     2588.49|IPCA|     -0.37|1743228352729|        0|\n",
      "|       6.39|1427068800000|  1723680000000|    1440.85|      1449.49|     1441.86|IPCA|      6.45|1743228352730|        0|\n",
      "|      -0.69|1426809600000|  1431648000000|    2584.96|      2588.42|     2588.34|IPCA|     -0.67|1743228352732|        0|\n",
      "|       6.32|1426809600000|  1557878400000|    2003.19|      2009.47|     2006.36|IPCA|      6.36|1743228352733|        0|\n",
      "|      -0.87|1426636800000|  1431648000000|    2583.52|      2584.66|     2584.58|IPCA|     -0.85|1743228352766|        0|\n",
      "|       6.22|1426636800000|  1723680000000|    1458.18|      1466.92|     1459.18|IPCA|      6.28|1743228352766|        0|\n",
      "|      10.18|1718668800000|  1723680000000|    4222.05|      4224.91|     4222.05|IPCA|      10.3|1743228344925|        0|\n",
      "|       6.46|1718668800000|  1873497600000|    3145.18|      3163.65|     3145.18|IPCA|      6.58|1743228344926|        0|\n",
      "|       4.32|1557446400000|  2378419200000|    1044.15|      1076.54|     1044.92|IPCA|      4.44|1743228349308|        0|\n",
      "|      -1.58|1557446400000|  1557878400000|     3222.4|      3224.08|     3224.04|IPCA|     -1.46|1743228349309|        0|\n",
      "+-----------+-------------+---------------+-----------+-------------+------------+----+----------+-------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bronze.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcd80e3a-797f-47e7-bee2-a5f8b0860345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbab2857-fc81-43f8-93ce-19e37762620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silver = df_bronze.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe956310-22c0-445a-980f-d6bd0a0adc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silver = df_silver.withColumn(\"Data_Vencimento\", from_unixtime(col(\"Data_Vencimento\") / 1000, \"yyyy-MM-dd\")) \\\n",
    ".withColumn(\"Data_Base\", from_unixtime(col(\"Data_Base\") / 1000, \"yyyy-MM-dd\")) \\\n",
    ".withColumn(\"dt_update\", from_unixtime(col(\"dt_update\") / 1000, \"yyyy-MM-dd HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "614c4d14-11e6-4d28-912c-0332ab3391bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silver = df_silver.fillna({\"PUCompraManha\": 0, \"PUVendaManha\": 0, \"PUBaseManha\": 0}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ab0236e-33a4-4c18-9694-498f7357324b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------------+-----------+-------------+------------+----+----------+-------------------+---------+\n",
      "|CompraManha| Data_Base|Data_Vencimento|PUBaseManha|PUCompraManha|PUVendaManha|Tipo|VendaManha|          dt_update|partition|\n",
      "+-----------+----------+---------------+-----------+-------------+------------+----+----------+-------------------+---------+\n",
      "|      -1.58|2019-05-10|     2019-05-15|     3222.4|      3224.08|     3224.04|IPCA|     -1.46|2025-03-29 06:05:49|        0|\n",
      "|      -0.69|2015-03-20|     2015-05-15|    2584.96|      2588.42|     2588.34|IPCA|     -0.67|2025-03-29 06:05:52|        0|\n",
      "|       6.16|2024-09-09|     2035-05-15|    2261.44|      2289.26|     2261.44|IPCA|      6.28|2025-03-29 06:05:44|        0|\n",
      "|      -0.54|2019-04-24|     2019-05-15|    3212.55|      3213.27|     3213.07|IPCA|     -0.42|2025-03-29 06:05:49|        0|\n",
      "|      10.18|2024-06-18|     2024-08-15|    4222.05|      4224.91|     4222.05|IPCA|      10.3|2025-03-29 06:05:44|        0|\n",
      "|      -0.99|2015-03-13|     2015-05-15|    2578.62|      2581.99|      2581.9|IPCA|     -0.97|2025-03-29 06:05:52|        0|\n",
      "|       4.38|2019-05-07|     2035-05-15|    1594.32|      1624.47|     1594.93|IPCA|       4.5|2025-03-29 06:05:49|        0|\n",
      "|      -0.99|2015-03-12|     2015-05-15|     2577.6|      2578.71|     2578.62|IPCA|     -0.97|2025-03-29 06:05:52|        0|\n",
      "|      -0.97|2015-03-17|     2015-05-15|    2582.87|       2584.0|     2583.92|IPCA|     -0.95|2025-03-29 06:05:52|        0|\n",
      "|       4.42|2019-05-03|     2035-05-15|    1582.77|      1613.35|      1584.0|IPCA|      4.54|2025-03-29 06:05:49|        0|\n",
      "|       4.16|2019-04-26|     2024-08-15|    2574.76|      2592.49|     2576.75|IPCA|      4.28|2025-03-29 06:05:49|        0|\n",
      "|       4.46|2019-04-24|     2045-05-15|    1003.38|      1034.13|     1003.74|IPCA|      4.58|2025-03-29 06:05:49|        0|\n",
      "|      -1.53|2019-05-08|     2019-05-15|     3222.5|      3223.04|     3222.98|IPCA|     -1.41|2025-03-29 06:05:49|        0|\n",
      "|      -0.38|2019-04-23|     2019-05-15|    3211.72|      3212.48|     3212.26|IPCA|     -0.26|2025-03-29 06:05:49|        0|\n",
      "|      -0.23|2019-04-12|     2019-05-15|    3204.59|       3207.2|     3206.89|IPCA|     -0.11|2025-03-29 06:05:49|        0|\n",
      "|      10.27|2024-06-24|     2024-08-15|    4230.97|      4233.79|     4230.97|IPCA|     10.39|2025-03-29 06:05:44|        0|\n",
      "|       4.04|2019-05-07|     2024-08-15|    2598.79|      2615.56|     2599.74|IPCA|      4.16|2025-03-29 06:05:49|        0|\n",
      "|       6.22|2015-03-18|     2024-08-15|    1458.18|      1466.92|     1459.18|IPCA|      6.28|2025-03-29 06:05:52|        0|\n",
      "|       0.07|2015-03-25|     2015-05-15|    2588.01|      2589.26|     2589.19|IPCA|      0.09|2025-03-29 06:05:52|        0|\n",
      "|      -1.54|2019-05-06|     2019-05-15|    3221.57|      3222.13|     3222.04|IPCA|     -1.42|2025-03-29 06:05:49|        0|\n",
      "+-----------+----------+---------------+-----------+-------------+------------+----+----------+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_silver.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "477089a2-a8db-46c0-8402-ec77b1051314",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_path = \"s3a://my-bucket-carlao-01/processed-data/ipca/silver/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c5f7fe1-151a-4a81-99d9-7e814e527f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silver.write.mode(\"overwrite\").parquet(silver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4f399e4-d808-440a-aaee-80cb86c09367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "523a829e-afe1-4681-9819-44f82cce398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold = df_silver.groupBy(\"Tipo\").agg(avg(\"PUCompraManha\").alias(\"Media_PUCompraManha\"), avg(\"PUVendaManha\").alias(\"Media_PUVendaManha\"), count(\"*\").alias(\"Total_Registros\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebdb599a-1562-4db4-b30c-9fb429971763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+------------------+---------------+\n",
      "|Tipo|Media_PUCompraManha|Media_PUVendaManha|Total_Registros|\n",
      "+----+-------------------+------------------+---------------+\n",
      "|IPCA|  1771.582629854369|1757.3804830097047|          16480|\n",
      "+----+-------------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_gold.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8372fe9c-d160-4d75-975c-b652081d3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_path = \"s3a://my-bucket-carlao-01/analytics/ipca/gold/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8b8c7c7-5354-4420-a32d-bfe8a43bab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold.write.mode(\"overwrite\").parquet(gold_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00fa26a1-8d87-4660-9904-07ce038c9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_columns = df_bronze.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5bd7d8b-5b0e-4158-9b7f-c33c42ce592f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CompraManha',\n",
       " 'Data_Base',\n",
       " 'Data_Vencimento',\n",
       " 'PUBaseManha',\n",
       " 'PUCompraManha',\n",
       " 'PUVendaManha',\n",
       " 'Tipo',\n",
       " 'VendaManha',\n",
       " 'dt_update',\n",
       " 'partition']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bronze_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6be0e97-3cb0-449f-a0e0-4edbb1c06538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------------+-----------+-------------+------------+----+----------+---------+---------+-----+\n",
      "|CompraManha|Data_Base|Data_Vencimento|PUBaseManha|PUCompraManha|PUVendaManha|Tipo|VendaManha|dt_update|partition|count|\n",
      "+-----------+---------+---------------+-----------+-------------+------------+----+----------+---------+---------+-----+\n",
      "+-----------+---------+---------------+-----------+-------------+------------+----+----------+---------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bronze.groupBy(bronze_columns).count().filter(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a143bc1a-87ec-46fd-8a4c-199a8621944b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------------+-----------+-------------+------------+----+----------+---------+---------+\n",
      "|CompraManha|Data_Base|Data_Vencimento|PUBaseManha|PUCompraManha|PUVendaManha|Tipo|VendaManha|dt_update|partition|\n",
      "+-----------+---------+---------------+-----------+-------------+------------+----+----------+---------+---------+\n",
      "+-----------+---------+---------------+-----------+-------------+------------+----+----------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bronze.filter(\n",
    "    col(\"PUCompraManha\").isNull() |\n",
    "    col(\"PUVendaManha\").isNull() |\n",
    "    col(\"PUBaseManha\").isNull()\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c65df-f47e-4075-aa77-d8db7799b044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
